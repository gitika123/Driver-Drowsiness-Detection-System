{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNXPYiSP7J8l"
      },
      "source": [
        "# Driver Drowsiness Detection - CNN Model\n",
        "## Complete Data Science Lifecycle Implementation\n",
        "\n",
        "This notebook implements a comprehensive CNN-based driver drowsiness detection system covering:\n",
        "- Complete EDA and data visualization\n",
        "- Data preprocessing and augmentation\n",
        "- Model development with MobileNetV2\n",
        "- Training and evaluation\n",
        "- Interactive dashboard with Gradio\n",
        "- Model interpretation and deployment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8vVUyPB7J8n"
      },
      "source": [
        "## 1. Installation and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IURKaxNS7J8n"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install tensorflow matplotlib scikit-learn keras_cv gradio pandas seaborn plotly opencv-python -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVPHJJX57J8o"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive (if using Colab)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    BASE_DIR = '/content/drive/MyDrive/cs163_ds'\n",
        "except:\n",
        "    # Local path - adjust as needed\n",
        "    BASE_DIR = '/Users/spartan/Downloads/cs163 Modules/project/cs163_ds'\n",
        "\n",
        "print(f\"Dataset directory: {BASE_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA3CGvIH7J8o"
      },
      "source": [
        "## 2. Data Loading and Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2J1tbj967J8p"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IntaVA_n7J8p"
      },
      "outputs": [],
      "source": [
        "# Dataset exploration\n",
        "def explore_dataset(base_dir):\n",
        "    \"\"\"Comprehensive dataset exploration\"\"\"\n",
        "    folders = [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]\n",
        "\n",
        "    dataset_info = {}\n",
        "    total_images = 0\n",
        "\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(base_dir, folder)\n",
        "        images = [f for f in os.listdir(folder_path)\n",
        "                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        dataset_info[folder] = {\n",
        "            'count': len(images),\n",
        "            'images': images[:5]  # Sample image names\n",
        "        }\n",
        "        total_images += len(images)\n",
        "\n",
        "    return folders, dataset_info, total_images\n",
        "\n",
        "folders, dataset_info, total_images = explore_dataset(BASE_DIR)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DATASET EXPLORATION\")\n",
        "print(\"=\"*60)\n",
        "for folder, info in dataset_info.items():\n",
        "    print(f\"{folder:20s}: {info['count']:5d} images\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total Images: {total_images}\")\n",
        "print(f\"Number of Classes: {len(folders)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeukhHCm7J8q"
      },
      "source": [
        "## 3. Exploratory Data Analysis (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rARrJfIa7J8r"
      },
      "outputs": [],
      "source": [
        "# 3.1 Class Distribution Visualization\n",
        "counts = Counter([dataset_info[f]['count'] for f in folders])\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.bar(folders, [dataset_info[f]['count'] for f in folders], color=sns.color_palette(\"husl\", len(folders)))\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Class Distribution in Dataset\", fontsize=14, fontweight='bold')\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('class_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOvZwDIZ7J8s"
      },
      "source": [
        "## 4. Data Preprocessing and Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU4xO0gL7J8s"
      },
      "outputs": [],
      "source": [
        "# Data preprocessing and augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    brightness_range=[0.7,1.3],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    BASE_DIR, target_size=(img_height, img_width), batch_size=batch_size,\n",
        "    class_mode='categorical', subset='training', shuffle=True\n",
        ")\n",
        "val_data = datagen.flow_from_directory(\n",
        "    BASE_DIR, target_size=(img_height, img_width), batch_size=batch_size,\n",
        "    class_mode='categorical', subset='validation', shuffle=False\n",
        ")\n",
        "labels = list(train_data.class_indices.keys())\n",
        "print(f\"Classes: {labels}\")\n",
        "print(f\"Training samples: {train_data.samples}\")\n",
        "print(f\"Validation samples: {val_data.samples}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNd6ImAK7J8t"
      },
      "outputs": [],
      "source": [
        "# Class weights for binary drowsiness\n",
        "drowsy_labels = ['Yawn', 'closed']\n",
        "train_bin = np.array([1 if labels[i] in drowsy_labels else 0 for i in train_data.classes])\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0,1]), y=train_bin)\n",
        "cw_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "print(\"Class weights for binary drowsiness:\", cw_dict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkDxvR0t7J8t"
      },
      "source": [
        "## 5. CNN Model Development (MobileNetV2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DurRIE7n7J8t"
      },
      "outputs": [],
      "source": [
        "# Build CNN model with MobileNetV2\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models, optimizers, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "base_model = MobileNetV2(input_shape=(img_height, img_width, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "model_cnn = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(96, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(train_data.num_classes, activation='softmax')\n",
        "])\n",
        "model_cnn.compile(optimizer=optimizers.Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r-iCF6U7J8u"
      },
      "source": [
        "## 6. Model Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHpXKnUp7J8u"
      },
      "source": [
        "## 6.5 Training History Visualization & Overfitting Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE6DEt9d7J8u"
      },
      "outputs": [],
      "source": [
        "# Visualize training history and detect overfitting\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training curves and analyze overfitting\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
        "\n",
        "    # Accuracy plot\n",
        "    axes[0].plot(epochs, history.history['accuracy'], 'o-', label='Train Accuracy', linewidth=2, markersize=8)\n",
        "    axes[0].plot(epochs, history.history['val_accuracy'], 's-', label='Val Accuracy', linewidth=2, markersize=8)\n",
        "    axes[0].set_title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "    axes[0].legend(fontsize=11)\n",
        "    axes[0].grid(alpha=0.3)\n",
        "    axes[0].set_ylim([0.95, 1.01])\n",
        "\n",
        "    # Loss plot\n",
        "    axes[1].plot(epochs, history.history['loss'], 'o-', label='Train Loss', linewidth=2, markersize=8)\n",
        "    axes[1].plot(epochs, history.history['val_loss'], 's-', label='Val Loss', linewidth=2, markersize=8)\n",
        "    axes[1].set_title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1].set_ylabel('Loss', fontsize=12)\n",
        "    axes[1].legend(fontsize=11)\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Analyze overfitting\n",
        "    print(\"=\"*60)\n",
        "    print(\"OVERFITTING ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    train_acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    train_loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    # Find best epoch\n",
        "    best_epoch = np.argmax(val_acc) + 1\n",
        "    best_val_acc = max(val_acc)\n",
        "    best_train_acc = train_acc[np.argmax(val_acc)]\n",
        "    best_val_loss = val_loss[np.argmax(val_acc)]\n",
        "    best_train_loss = train_loss[np.argmax(val_acc)]\n",
        "\n",
        "    # Final epoch metrics\n",
        "    final_train_acc = train_acc[-1]\n",
        "    final_val_acc = val_acc[-1]\n",
        "    final_train_loss = train_loss[-1]\n",
        "    final_val_loss = val_loss[-1]\n",
        "\n",
        "    # Calculate gaps\n",
        "    acc_gap_best = best_train_acc - best_val_acc\n",
        "    acc_gap_final = final_train_acc - final_val_acc\n",
        "    loss_gap_best = abs(best_train_loss - best_val_loss)\n",
        "    loss_gap_final = abs(final_train_loss - final_val_loss)\n",
        "\n",
        "    print(f\"Best Model Performance (Epoch {best_epoch}):\")\n",
        "    print(f\"  Train Accuracy: {best_train_acc*100:.2f}%\")\n",
        "    print(f\"  Val Accuracy:   {best_val_acc*100:.2f}%\")\n",
        "    print(f\"  Accuracy Gap:   {acc_gap_best*100:.2f}%\")\n",
        "    print(f\"  Train Loss:     {best_train_loss:.4f}\")\n",
        "    print(f\"  Val Loss:       {best_val_loss:.4f}\")\n",
        "    print(f\"  Loss Gap:       {loss_gap_best:.4f}\")\n",
        "\n",
        "    print(f\"\\nFinal Epoch Performance:\")\n",
        "    print(f\"  Train Accuracy: {final_train_acc*100:.2f}%\")\n",
        "    print(f\"  Val Accuracy:   {final_val_acc*100:.2f}%\")\n",
        "    print(f\"  Accuracy Gap:   {acc_gap_final*100:.2f}%\")\n",
        "    print(f\"  Train Loss:     {final_train_loss:.4f}\")\n",
        "    print(f\"  Val Loss:       {final_val_loss:.4f}\")\n",
        "    print(f\"  Loss Gap:       {loss_gap_final:.4f}\")\n",
        "\n",
        "    # Overfitting indicators\n",
        "    print(f\"\\n\" + \"=\"*60)\n",
        "    print(\"OVERFITTING INDICATORS:\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    overfitting_signs = []\n",
        "\n",
        "    if final_train_acc >= 1.0:\n",
        "        overfitting_signs.append(\"‚ö†Ô∏è  Training accuracy reached 100% (perfect memorization)\")\n",
        "\n",
        "    if acc_gap_final > acc_gap_best + 0.01:\n",
        "        overfitting_signs.append(f\"‚ö†Ô∏è  Accuracy gap increased by {abs(acc_gap_final - acc_gap_best)*100:.2f}%\")\n",
        "\n",
        "    if final_val_loss > best_val_loss:\n",
        "        overfitting_signs.append(f\"‚ö†Ô∏è  Validation loss increased from {best_val_loss:.4f} to {final_val_loss:.4f}\")\n",
        "\n",
        "    if final_val_acc < best_val_acc:\n",
        "        overfitting_signs.append(f\"‚ö†Ô∏è  Validation accuracy decreased from {best_val_acc*100:.2f}% to {final_val_acc*100:.2f}%\")\n",
        "\n",
        "    if len(overfitting_signs) == 0:\n",
        "        print(\"‚úì No significant overfitting detected!\")\n",
        "        print(\"  The model generalizes well to validation data.\")\n",
        "    else:\n",
        "        print(f\"Found {len(overfitting_signs)} indicator(s) of overfitting:\")\n",
        "        for sign in overfitting_signs:\n",
        "            print(f\"  {sign}\")\n",
        "\n",
        "        if len(overfitting_signs) >= 2:\n",
        "            severity = \"MODERATE\"\n",
        "        else:\n",
        "            severity = \"MILD\"\n",
        "\n",
        "        print(f\"\\nüìä Overfitting Severity: {severity}\")\n",
        "        print(f\"\\nüí° Recommendations:\")\n",
        "        print(\"  1. Use the model from Epoch {} (best validation performance)\".format(best_epoch))\n",
        "        print(\"  2. Increase dropout rates (currently 0.5)\")\n",
        "        print(\"  3. Add more data augmentation\")\n",
        "        print(\"  4. Increase L2 regularization\")\n",
        "        print(\"  5. Reduce model capacity if needed\")\n",
        "        print(\"  6. Use early stopping (already implemented)\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return best_epoch, best_val_acc\n",
        "\n",
        "# Plot and analyze\n",
        "best_epoch, best_val_acc = plot_training_history(cnn_hist)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilYE2C9M7J8v"
      },
      "source": [
        "## 6.6 Load Best Model (Non-Overfit Version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J3_yJLq7J8v"
      },
      "outputs": [],
      "source": [
        "# The ModelCheckpoint callback already saved the best model (with lowest val_loss)\n",
        "# Reload it to ensure we're using the non-overfit version\n",
        "print(f\"Loading best model saved at: {checkpoint_path}\")\n",
        "print(f\"This model has the best validation performance (Epoch {best_epoch})\")\n",
        "print(f\"Validation Accuracy: {best_val_acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cIYoUcs7J8v"
      },
      "source": [
        "## 5.5 Alternative: Improved Model with Anti-Overfitting Techniques\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KPmBISc7J8v"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: Improved model with stronger regularization to reduce overfitting\n",
        "# Uncomment and use this if you want to retrain with anti-overfitting measures\n",
        "\n",
        "\"\"\"\n",
        "# Build improved CNN model with stronger regularization\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models, optimizers, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "base_model_improved = MobileNetV2(input_shape=(img_height, img_width, 3), include_top=False, weights='imagenet')\n",
        "base_model_improved.trainable = False\n",
        "\n",
        "model_cnn_improved = models.Sequential([\n",
        "    base_model_improved,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.6),  # Increased from 0.5\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.02)),  # Stronger L2\n",
        "    layers.BatchNormalization(),  # Added batch normalization\n",
        "    layers.Dropout(0.6),  # Increased dropout\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.02)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(train_data.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model_cnn_improved.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_cnn_improved.summary()\n",
        "\n",
        "# This improved model uses:\n",
        "# - Higher dropout rates (0.6 instead of 0.5)\n",
        "# - Stronger L2 regularization (0.02 instead of 0.01)\n",
        "# - Batch normalization for stability\n",
        "# - Additional dense layer for better feature extraction\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_510yMeq7J8v"
      },
      "outputs": [],
      "source": [
        "# Training callbacks\n",
        "checkpoint_path = 'best_cnn_model.keras'\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, monitor='val_loss', verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6, verbose=1)\n",
        "]\n",
        "\n",
        "# Train model\n",
        "cnn_hist = model_cnn.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=20,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Vf8SLb7J8v"
      },
      "source": [
        "## 7. Model Evaluation and Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gls-k_xE7J8w"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "val_data.reset()\n",
        "Y_pred = model_cnn.predict(val_data, verbose=1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "y_true = val_data.classes\n",
        "\n",
        "print(\"Multiclass Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=labels))\n",
        "\n",
        "# Binary drowsiness evaluation\n",
        "y_true_bin = [1 if labels[i] in drowsy_labels else 0 for i in y_true]\n",
        "y_pred_bin = [1 if labels[i] in drowsy_labels else 0 for i in y_pred]\n",
        "print(\"\\nBinary Drowsiness Classification Report:\")\n",
        "print(classification_report(y_true_bin, y_pred_bin, target_names=['Not Drowsy', 'Drowsy']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS1eabns7J8w"
      },
      "source": [
        "## 8. Interactive Dashboard with Gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HByTK4h97J8w"
      },
      "outputs": [],
      "source": [
        "# Install Gradio if needed\n",
        "%pip install gradio -q\n",
        "\n",
        "import gradio as gr\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_image(model, img_path):\n",
        "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "    img_array = image.img_to_array(img) / 255.\n",
        "    img_array = np.expand_dims(img_array, 0)\n",
        "    pred = model.predict(img_array, verbose=0)\n",
        "    return labels[np.argmax(pred)], pred\n",
        "\n",
        "def classify_image_gradio(img_path):\n",
        "    if img_path is None:\n",
        "        return None, None, None\n",
        "\n",
        "    pred_class, raw_predictions = predict_image(model_cnn, img_path)\n",
        "    binary_status = \"Drowsy\" if pred_class in drowsy_labels else \"Not Drowsy\"\n",
        "    class_probs = {labels[i]: float(raw_predictions[0][i]) for i in range(len(labels))}\n",
        "\n",
        "    output_text = f\"**Predicted Class:** {pred_class}\\\\n**Drowsiness Status:** {binary_status}\"\n",
        "    return output_text, pred_class, class_probs\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=classify_image_gradio,\n",
        "    inputs=gr.Image(type=\"filepath\"),\n",
        "    outputs=[\n",
        "        gr.Markdown(label=\"Prediction Results\"),\n",
        "        gr.Textbox(label=\"Predicted Class\"),\n",
        "        gr.Label(label=\"Class Probabilities\")\n",
        "    ],\n",
        "    title=\"üöó Driver Drowsiness Detection Dashboard\",\n",
        "    description=\"Upload an image to predict the driver's activity and drowsiness status.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=False, server_name=\"0.0.0.0\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
